## Introduction

### Goals

- Learn about the definition of Reinforcement Learning (RL) problem and its key elements.
- Early history of RL and how the field evolved over time.

### Summary

- RL is learning from interactions, how to map situations to actions, to maximize rewards.
- Key distinguishing features: trial-and-error search and delayed reward. In supervised learning, we have the label,
which is a specification of correct action for a particular sitation, while in RL, it often learnt from interaction with
environment
- Three important aspects of an RL agent: sensation, action, goal.
- Elements of RL: agent and environment, subelements: policy, reward, value function, model of environment.

- Reinforcement Learning (RL) is concerned with goal-directed learning and decision-making.
- In RL an agent learns from experiences it gains by interacting with the environment. In Supervised Learning we cannot affect the environment.
- In RL rewards are often delayed in time and the agent tries to maximize a long-term goal. For example, one may need to make seemingly suboptimal moves to reach a winning position in a game.
- An agent interacts with the environment via states, actions and rewards.


### Lectures & Readings

- [Reinforcement Learning: An Introduction](http://incompleteideas.net/book/bookdraft2018jan1.pdf) - Chapter 1: Introduction
- David Silver's RL Course Lecture 1 - Introduction to Reinforcement Learning ([video](https://www.youtube.com/watch?v=2pWv7GOvuf0), [slides](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/intro_RL.pdf))
<!---
- [OpenAI Gym Tutorial](https://gym.openai.com/docs)
-->

### Exercises

- [Chapter 1 Exercises](Chaper1-Exercises.md)
<!---
- [Work through the OpenAI Gym Tutorial](https://gym.openai.com/docs)
-->
